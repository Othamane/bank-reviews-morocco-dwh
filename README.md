# Analyzing Customer Reviews of Bank Agencies in Morocco using a Modern Data Stack

## Student Profile
**Name:** NOURDDINE Othmane
**Program:** Master 2 â€“ SystÃ¨mes d'Information et SystÃ¨mes Intelligents (M2SI)
**Institution:**Institut National de Statistique et d'Ã‰conomie AppliquÃ©e (INSEA)
**Academic Year:** 2024-2025
**Project Type:** Data Engineering & Analytics Capstone Project

## Project Overview

**Objective:**
Collect, process, and analyze Google Maps reviews for bank agencies in Morocco to extract valuable insights using topic modeling, sentiment detection, and other key metrics. Build a fully operational data pipeline using modern tools for efficient data extraction, transformation, storage, and visualization.

## Table of Contents

1. [Project Overview](#project-overview)
2. [Project Scope](#project-scope)
3. [Technology Stack](#technology-stack)
4. [Project Roadmap](#project-roadmap)
5. [Deliverables](#deliverables)

---

## Project Scope

Banks receive thousands of customer reviews on Google Maps. These reviews contain valuable insights about customer satisfaction, service quality, and common issues, but they are unstructured and dispersed. This project centralizes, cleans, and analyzes these reviews to provide actionable insights.

**Expected Insights:**

* **Sentiment Analysis:** Trends in customer satisfaction over time.
* **Topic Modeling:** Common praise points and recurring issues.
* **Branch Performance:** Ranking of bank agencies based on aggregate sentiment.
* **Customer Experience Metrics:** Identification of frequent complaints and satisfaction drivers.

---

## Technology Stack

| Stage               | Technology                                    |
| ------------------- | --------------------------------------------- |
| **Data Collection** | Python, Google Maps API, BeautifulSoup/Scrapy |
| **Scheduling**      | Apache Airflow                                |
| **Data Storage**    | PostgreSQL (Data Warehouse)                   |
| **Transformation**  | DBT (Data Build Tool)                         |
| **Analysis & BI**   | Looker Studio (Google Data Studio)            |
| **Version Control** | GitHub                                        |

## Folder Structure

ğŸ“ Project Root 
â”œâ”€â”€ ğŸ“ .dbt/                          # DBT configuration files
â”œâ”€â”€ ğŸ“ airflow/                       # Airflow orchestration
â”‚   â”œâ”€â”€ ğŸ“ dags/                      # DAG definitions
â”œâ”€â”€ ğŸ“ Dashboard_images/              # Dashboard screenshots
â”œâ”€â”€ ğŸ“ data_warehouse_project/        # DBT project
â”‚   â”œâ”€â”€ ğŸ“ analyses/                  # Ad-hoc analyses
â”‚   â”œâ”€â”€ ğŸ“ logs/                      # DBT logs
â”‚   â”œâ”€â”€ ğŸ“ macros/                    # DBT macros
â”‚   â”œâ”€â”€ ğŸ“ models/                    # DBT models
â”‚   â”‚   â”œâ”€â”€ ğŸ“ marts/                 # Data mart models
â”‚   â”‚   â””â”€â”€ ğŸ“ sources/               # Source definitions
â”‚   â”œâ”€â”€ ğŸ“ seeds/                     # Static data files
â”‚   â”œâ”€â”€ ğŸ“ snapshots/                 # Data snapshots
â”‚   â”œâ”€â”€ ğŸ“ target/                    # DBT compiled files
â”‚   â”‚   â”œâ”€â”€ ğŸ“ compiled/              # Compiled SQL
â”‚   â”‚   â””â”€â”€ ğŸ“ run/                   # Execution results
â”‚   â””â”€â”€ ğŸ“ tests/                     # Data quality tests
â””â”€â”€ ğŸ“„ README.md                      # Project documentation



## Project Roadmap

The project is structured into six main phases:

### Phase 1: Data Collection (âœ… Completed)

1. **Extract Reviews:**

   * Use Google Maps API or web scraping to collect reviews for major bank agencies in Morocco.
   * Capture: Bank name, branch name, location, review text, rating, review date.
   * Save raw data in JSON/CSV files.
2. **Automation with Airflow:**

   * Configure an Airflow DAG to schedule data extraction daily or weekly.
   * Load raw data into a PostgreSQL staging table.

### Phase 2: Data Cleaning & Transformation (âœ… Completed)

1. **Cleaning (DBT & SQL):**

   * Deduplicate records.
   * Normalize text (lowercase, remove punctuation & stop words).
   * Handle missing or null values.
2. **Enrichment:**

   * Detect language of each review.
   * Classify sentiment as *Positive*, *Negative*, or *Neutral*.
   * Perform topic extraction using LDA for common themes.

### Phase 3: Data Modeling (âœ… Completed)

1. **Star Schema Design:**

   * **Fact Table:** `fact_reviews` (metrics per review).
   * **Dimension Tables:** `dim_bank`, `dim_branch`, `dim_location`, `dim_sentiment`.
2. **Implementation:**

   * Build DBT models to transform and load data into the warehouse.
   * Automate loading via Airflow DAGs.



### Phase 4: Data Analytics & Reporting (âœ… Completed)

* Develop interactive dashboards in Looker Studio:

  * Sentiment trends by bank and branch.
  * Top positive and negative topics.
  * Branch performance rankings.
  * Key customer experience insights.

### Phase 5: Deployment & Automation

1. **Pipeline Automation:**

   * Ensure Airflow DAGs run on schedule (daily/weekly updates).
   * Configure alerts for data failures or anomalies.

---

## Deliverables

### PhaseÂ 1: Data Collection & Loading

1. **main\_scraping\_script.py**

   * **RÃ´leÂ :** Script principal de collecte des avis Google Maps pour une liste de banques marocaines.
   * **TechnologiesÂ :** PythonÂ 3, Selenium, BeautifulSoup4, webdriver-manager, Chrome.
   * **FonctionnalitÃ©s clÃ©sÂ :**

     * Initialisation et configuration du driver Chrome.
     * Navigation et dÃ©filement dynamiques pour charger tous les avis.
     * Extraction des liens dâ€™agences, noms, adresses et avis (texte, note, date).
     * ContrÃ´les dâ€™erreur et pauses alÃ©atoires pour limiter la dÃ©tection.
   * **EntrÃ©e / SortieÂ :**

     * Liste de banques en dur dans le script.
     * GÃ©nÃ©ration de `moroccan_banks_reviews.json` dans `~/input/data_of_json_google_map/`.

2. **insert\_data.py**

   * **RÃ´leÂ :** Chargement du JSON brut dans la table `staging` PostgreSQL.
   * **TechnologiesÂ :** PythonÂ 3, psycopg2.
   * **FonctionnalitÃ©s clÃ©sÂ :**

     * CrÃ©ation/rafraÃ®chissement de la table `staging`.
     * Parsing du JSON de scraping.
     * Insertion des champs (banque, agence, emplacement, texte dâ€™avis, note, date) avec date de scraping.
     * Gestion des erreurs de connexion, dÃ©codage JSON et insertion, rollback en cas dâ€™erreur.

**Orchestration Airflow (PhaseÂ 1)**

```python
scraping_task = PythonOperator(
    task_id='extract_data_task',
    python_callable=lambda: __import__('main_scraping_script').main(),
    dag=dag
)
insertion_task = PythonOperator(
    task_id='insert_data_task',
    python_callable=lambda: __import__('insert_data').main(),
    dag=dag
)
scraping_task >> insertion_task
```

### PhaseÂ 2: Data Cleaning & Transformation

1. **cleaned\_reviews.sql**

   * **RÃ´leÂ :** ModÃ¨le DBT de nettoyage et normalisation des donnÃ©es issues de `staging`.
   * **Ã‰tapes clÃ©sÂ :** suppression des doublons, normalisation du texte (minuscules, suppression des caractÃ¨res spÃ©ciaux), gestion des valeurs manquantes, dÃ©tection/filtrage des langues (FR/EN), conversion des notes en entiers, ajustement des dates relatives via le macro `convert_relative_date`.

2. **sources.yml**

   * **RÃ´leÂ :** DÃ©finition de la source `raw_data.staging` pour DBT.

3. **transform\_phase\_2.py**

   * **RÃ´leÂ :** Enrichissement de la table `cleaned_reviews` avec dÃ©tection de la langue, analyse de sentiments et modÃ©lisation de sujets via LDA.
   * **TechnologiesÂ :** PythonÂ 3, pandas, SQLAlchemy, psycopg2, transformers, langdetect, NLTK, gensim.
   * **FonctionnalitÃ©s clÃ©sÂ :** ajout de colonnes `language`, `sentiment`, `relative_topic`, `topic_meaning`, filtrage des avis contenants du script arabe, mise Ã  jour incrÃ©mentale des donnÃ©es.

**Orchestration Airflow (PhaseÂ 2)**

```python
transform_phase_1_task = BashOperator(
    task_id='transform_phase_1_task',
    bash_command='cd ~/data_warehouse_project && dbt run --models cleaned_reviews',
    dag=dag
)
transform_phase_2_task = PythonOperator(
    task_id='transform_phase_2_task',
    python_callable=lambda: __import__('transform_phase_2').main(),
    dag=dag
)
transform_phase_1_task >> transform_phase_2_task
```

### PhaseÂ 3: Data Modeling

1. **dim\_bank.sql**, **dim\_branch.sql**, **dim\_location.sql**, **dim\_sentiment.sql**

   * **RÃ´leÂ :** CrÃ©ation des tables de dimensions (`bank_id`, `branch_id`, `location_id`, `sentiment_id`) avec clÃ©s primaires et donnÃ©es distinctes provenant de `cleaned_reviews`.

2. **fact\_reviews.sql**

   * **RÃ´leÂ :** Construction de la table de faits `fact_reviews` via jointures sur les dimensions, gÃ©nÃ©ration de la clÃ© `fact_review_id` et dÃ©finition des clÃ©s Ã©trangÃ¨res.

3. **profiles.yml**

   * **RÃ´leÂ :** Configuration des connexions DBT pour les schÃ©mas `public` (raw & transformations) et `Decisionnelle` (Data Mart).

**Orchestration Airflow (PhaseÂ 3)**

```python
load_phase_task = BashOperator(
    task_id='load_phase_task',
    bash_command='cd ~/data_warehouse_project && dbt run --profile decisionnelle_profile --models dim_bank dim_branch dim_location dim_sentiment fact_reviews',
    dag=dag
)
transform_phase_2_task >> load_phase_task
```

Star Schema Diagram

Below is the star schema design for the data mart, showing the central fact table and its relationships to dimension tables:

![alt text](DW_Schema.png)

Explanation: The fact_reviews table sits at the center, linking to four dimensions:

dim_bank: Contains unique banks (bank_id, bank_name).

dim_branch: Contains branches (branch_id, branch_name).

dim_location: Geographic information (location_id, location).

dim_sentiment: Sentiment labels (sentiment_id, sentiment_label).

This design enables efficient slicing and dicing of review data by bank, branch, location, or sentiment for BI queries.   

### PhaseÂ 4: Data Analytics & Reporting
![alt text](Dashboard_images/Dashboard.png)

1. Distribution des agences bancaires : Cette carte montre la rÃ©partition gÃ©ographique des agences bancaires au Maroc. Les points sur la carte indiquent les emplacements des agences, avec une concentration notable autour des zones urbaines comme Casablanca, Rabat et Marrakech.
![alt text](Dashboard_images/image.png)


2. Distribution des topics : Ce graphique en barres horizontales illustre la rÃ©partition des sujets mentionnÃ©s dans les avis, divisÃ©s en trois catÃ©gories : Positif (bleu), NÃ©gatif (orange) et Neutre (violet). Le sujet "QualitÃ©" domine avec une majoritÃ© d'avis positifs, suivi de "Service" avec une part notable d'avis nÃ©gatifs.
![alt text](Dashboard_images/image-1.png)

3. Distribution des sentiments : Ce graphique en camembert prÃ©sente la rÃ©partition des sentiments dans les avis : 50,8 % positifs (bleu), 44,9 % nÃ©gatifs (orange) et 4,3 % neutres (violet), offrant une vue d'ensemble de la satisfaction client.
![alt text](Dashboard_images/image-2.png)
4. Rating Distribution par agence : Ce graphique en barres empilÃ©es montre la distribution des notes (1 Ã  5) pour chaque agence bancaire. Chaque barre reprÃ©sente une agence, avec des couleurs indiquant les diffÃ©rentes notes, permettant d'identifier les performances relatives.
![alt text](Dashboard_images/image-3.png)
5. Nombre d'avis par banque : Ce graphique en barres verticales affiche le nombre total d'avis par banque. Les banques comme Bank Assafa (Banque A) et BCP (Banque C) ont le plus grand nombre d'avis, tandis que d'autres comme SociÃ©tÃ© G en ont moins.
![alt text](Dashboard_images/image-4.png)
6. Tendance des sentiments par agence : Ce graphique en barres horizontales montre l'Ã©volution des sentiments (Positif en bleu, NÃ©gatif en orange, Neutre en violet) pour diffÃ©rentes agences. La majoritÃ© des agences, comme BCP - 101 bd Mohamed Zerktouni, Casablanca (Banque C) et Bank Assafa - Agadir, Rue de Marrakech (Banque A), ont une tendance majoritairement positive.
![alt text](Dashboard_images/image-5.png)
7. Distribution des ratings : Ce graphique en camembert indique la rÃ©partition des notes globales : 1 (46,3 %), 2 (0,5 %), 3 (3,3 %), 4 (7,8 %), 5 (42,1 %), reflÃ©tant la satisfaction gÃ©nÃ©rale.
![alt text](Dashboard_images/image-6.png)
8. Distribution des langues : Ce graphique en camembert montre que 87 % des avis sont en franÃ§ais (bleu), avec une minoritÃ© dans d'autres langues (orange), soulignant la langue dominante des clients.
![alt text](Dashboard_images/image-7.png)
9. Sentiment Flow par agence : Ce graphique en bande montre le flux des sentiments (Positif en bleu, NÃ©gatif en orange, Neutre en violet) pour diverses agences, avec des dÃ©tails sur les adresses spÃ©cifiques, offrant une analyse dÃ©taillÃ©e par emplacement.
![alt text](Dashboard_images/image-8.png)



### PhaseÂ 5: Pipeline ComplÃ¨te (DAG Airflow)

1. **google\_map\_dag\_etl.py**

   * **RÃ´leÂ :** Orchestration complÃ¨te de lâ€™ETL via Airflow : collecte, chargement, nettoyage, enrichissement, modÃ©lisation et chargement dans le Data Mart.
   * **TechnologiesÂ :** Airflow (PythonOperator, BashOperator), DBT, scripts Python (main\_scraping\_script.py, insert\_data.py, transform\_phase\_2.py).

```python
import os
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator

default_args = {
    'owner': 'master_m2si',
    'depends_on_past': False,
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'Google_map',
    default_args=default_args,
    description='Extraction & Insertion of Google Maps Reviews into PostgreSQL',
    start_date=datetime(2025, 3, 13),
    schedule_interval=None,
    catchup=False
) as dag:

    scraping_task = PythonOperator(
        task_id='extract_data_task',
        python_callable=lambda: __import__('main_scraping_script').main(), dag=dag
    )
    insertion_task = PythonOperator(
        task_id='insert_data_task',
        python_callable=lambda: __import__('insert_data').main(), dag=dag
    )
    transform_phase_1_task = BashOperator(
        task_id='transform_phase_1_task',
        bash_command='cd ~/data_warehouse_project && dbt run --models cleaned_reviews',
        dag=dag
    )
    transform_phase_2_task = PythonOperator(
        task_id='transform_phase_2_task',
        python_callable=lambda: __import__('transform_phase_2').main(), dag=dag
    )
    load_phase_task = BashOperator(
        task_id='load_phase_task',
        bash_command='cd ~/data_warehouse_project && dbt run --profile decisionnelle_profile --models dim_bank dim_branch dim_location dim_sentiment fact_reviews',
        dag=dag
    )

    scraping_task >> insertion_task >> transform_phase_1_task >> transform_phase_2_task >> load_phase_task
```
